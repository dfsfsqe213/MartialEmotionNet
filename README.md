# Martial Arts Emotion-Regulation Training

This repository contains the implementation and experimental framework for the study:

**"Research on the Impact of Martial Arts Explosive Action Training Based on Deep Learning on Individual Emotion Regulation and Attention Level"**

## Overview

This project proposes an integrated deep learning-based system to analyze and enhance individual emotion regulation and attention levels through martial arts explosive action training. By leveraging spatiotemporal perception networks and adaptive viewpoint optimization, the framework dynamically captures complex physical and emotional patterns during physical activity.

## Key Components

- **Trajectory-Aware Spatiotemporal Perception Network (TASPN)**  
  Captures dynamic motion trajectories and spatial features from martial arts actions.

- **Dynamic Viewpoint Induced Optimization (DVIO)**  
  Enhances viewpoint selection and uncertainty-aware attention mechanisms to improve interpretability and feedback relevance.

## Objective

To build a data-driven model that:

- Analyzes emotional and attentional states from motion data
- Enhances cognitive and affective performance in human-centric training
- Enables real-time assessment and adaptive feedback in martial arts education

## Experimental Results

The proposed framework demonstrates significant improvements in:

- Emotion regulation prediction accuracy  
- Attention level tracking consistency  
- Personalization and adaptability of training feedback

## Technologies

- Python / PyTorch  
- Human pose estimation (OpenPose / MediaPipe)  
- Spatiotemporal graph modeling  
- Deep learning-based behavior analysis  

## Structure

